{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raja-jamwal/blog-building-agentic-architectures/blob/main/langchain/Part_7_Evaluation%2C_Prioritization%2C_and_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9gcsINCmA45"
      },
      "source": [
        "# Building Agents in Python and n8n in 2026\n",
        "Companion to https://rajajamwal.substack.com/p/building-agents-in-python-and-n8n\n",
        "\n",
        "Subscribe to my blog, https://rajajamwal.substack.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foT8jJQlAD_"
      },
      "source": [
        "## Evaluation, Prioritization, and Exploration\n",
        "\n",
        "This is the **Final Chapter**.\n",
        "\n",
        "We have built agents that can chain, route, reflect, collaborate, and use tools. We have secured them with guardrails and optimized them for cost.\n",
        "\n",
        "Now, we face the final challenge: **How do we know if it's working?** And how do we make the agent work on the *right* things?\n",
        "\n",
        "We will cover:\n",
        "1.  **Evaluation (LLM-as-a-Judge):** Building an automated pipeline where one AI grades another AI's work.\n",
        "2.  **Prioritization:** Teaching an agent to rank tasks based on urgency and impact.\n",
        "3.  **Exploration:** Creating an agent that proactively seeks new information (the \"Scientist\" pattern).\n",
        "\n",
        "### The Stack\n",
        "*   **Python**\n",
        "*   **LangChain**\n",
        "*   **OpenAI** (GPT-4o-mini)\n",
        "\n",
        "### The n8n Connection\n",
        "*   **Evaluation** = Create a \"Test Workflow\". It runs your main agent, captures the output, and passes it to a second AI Agent node with a \"Grading Rubric\" prompt.\n",
        "*   **Prioritization** = An AI Agent node that takes a JSON list of tasks and outputs a sorted JSON list. You then use the **Split In Batches** node to process the top priority items first.\n",
        "*   **Exploration** = A loop where the AI generates search queries, fetches results (HTTP Request), and then uses those results to generate *new* queries (Loop Node)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seqOFdrymAUE",
        "outputId": "c14f913d-bb3a-46fc-d843-7dd3c3e5ed11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/84.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/489.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hEnter your OpenAI API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… Environment Setup Complete.\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Install Dependencies\n",
        "!pip install -qU langchain langchain-openai langchain-core\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# @title 2. Setup API Key\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")\n",
        "\n",
        "# Initialize the Model\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "print(\"âœ… Environment Setup Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufIKddW0mhBH"
      },
      "source": [
        "## Pattern 19: Evaluation (LLM-as-a-Judge)\n",
        "\n",
        "**The Problem:** In traditional software, unit tests pass or fail (True/False). In AI, the output is text. How do you \"test\" if a summary is \"good\"?\n",
        "\n",
        "**The Solution:** **LLM-as-a-Judge**. We use a strong model (the Judge) to evaluate the output of our worker model based on a specific rubric (Accuracy, Tone, Conciseness).\n",
        "\n",
        "**The Scenario:** We have a \"Junior Support Agent\" answering questions. We will build a \"Senior Auditor\" to grade its answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D82-GBrLmh1K",
        "outputId": "61b13881-fa05-4302-c145-ce5e069e0477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ğŸ§ª Starting Evaluation Loop ---\n",
            "\n",
            "ğŸ“ Question: How do I reset my password?\n",
            "ğŸ¤– Agent Answer: To reset your password, go to the login page and click on the \"Forgot Password?\" link. Follow the instructions sent to your email to create a new password.\n",
            "âš–ï¸ Judge Verdict:\n",
            "Score: 5  \n",
            "Reasoning: The answer is accurate, polite, and provides clear instructions that effectively solve the problem of resetting a password.\n",
            "\n",
            "ğŸ“ Question: Your product is garbage and I hate it!\n",
            "ğŸ¤– Agent Answer: I'm sorry to hear that you're not satisfied with our product. Your feedback is important to us, and weâ€™d like to help resolve any issues youâ€™re experiencing. Please let us know what specifically you dislike, and weâ€™ll do our best to assist you.\n",
            "âš–ï¸ Judge Verdict:\n",
            "Score: 5  \n",
            "Reasoning: The agent's response is accurate in acknowledging the customer's dissatisfaction, polite in its tone, and helpful by inviting the customer to provide more details for resolution.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# --- 1. The Subject (The Agent being tested) ---\n",
        "student_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Answer this customer question briefly: {question}\"\n",
        ")\n",
        "student_chain = student_prompt | llm | StrOutputParser()\n",
        "\n",
        "# --- 2. The Judge (The Evaluator) ---\n",
        "judge_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are a Quality Assurance Auditor.\n",
        "    Grade the following answer on a scale of 1 to 5 based on these criteria:\n",
        "    1. Accuracy (Is it true?)\n",
        "    2. Politeness (Is it nice?)\n",
        "    3. Helpfulness (Does it solve the problem?)\n",
        "\n",
        "    Question: {question}\n",
        "    Agent Answer: {answer}\n",
        "\n",
        "    Format:\n",
        "    Score: [1-5]\n",
        "    Reasoning: [One sentence explanation]\n",
        "    \"\"\"\n",
        ")\n",
        "judge_chain = judge_prompt | llm | StrOutputParser()\n",
        "\n",
        "# --- Execution ---\n",
        "questions = [\n",
        "    \"How do I reset my password?\",\n",
        "    \"Your product is garbage and I hate it!\"\n",
        "]\n",
        "\n",
        "print(\"--- ğŸ§ª Starting Evaluation Loop ---\")\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"\\nğŸ“ Question: {q}\")\n",
        "\n",
        "    # Step 1: Generate Answer\n",
        "    answer = student_chain.invoke({\"question\": q})\n",
        "    print(f\"ğŸ¤– Agent Answer: {answer}\")\n",
        "\n",
        "    # Step 2: Evaluate\n",
        "    evaluation = judge_chain.invoke({\"question\": q, \"answer\": answer})\n",
        "    print(f\"âš–ï¸ Judge Verdict:\\n{evaluation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qO1hHIEnB0V"
      },
      "source": [
        "## Pattern 20: Prioritization (The Strategist)\n",
        "\n",
        "**The Problem:** An agent receives 50 emails. If it processes them in order, it might spend all its time on spam and miss the urgent \"Server Down\" alert.\n",
        "\n",
        "**The Solution:** **The Triage Step**. Before doing any work, the agent analyzes the queue and assigns a \"Priority Score\" to each item. It then sorts the list.\n",
        "\n",
        "**The Scenario:** We have a list of support tickets. The agent must sort them so we handle the fires first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0osn9iXCnCPx",
        "outputId": "236f6e6a-ed54-4f2f-9f4c-a135c0450c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ğŸ“¥ Incoming Tickets (Unsorted) ---\n",
            "- I can't change my profile picture color\n",
            "- URGENT: The payment gateway is down, losing money!\n",
            "- Feature request: Dark mode\n",
            "- Security Alert: Suspicious login detected\n",
            "\n",
            "--- ğŸ§  Agent Prioritizing... ---\n",
            "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Raw Output: Here is the analysis of the tickets with assigned priorities:\n",
            "\n",
            "1. Ticket 2: \"URGENT: The payment gateway is down, losing money!\" - This is a high priority as it directly affects revenue and requires immediate attention.\n",
            "2. Ticket 4: \"Security Alert: Suspicious login detected\" - This is also a high priority due to the potential security risk involved.\n",
            "3. Ticket 1: \"I can't change my profile picture color\" - This is a medium priority as it affects user experience but does not have immediate consequences.\n",
            "4. Ticket 3: \"Feature request: Dark mode\" - This is a low priority as it is a request for a new feature rather than an issue that needs urgent resolution.\n",
            "\n",
            "Here is the JSON list of the tickets sorted by priority:\n",
            "\n",
            "```json\n",
            "[\n",
            "    {\"id\": 2, \"subject\": \"URGENT: The payment gateway is down, losing money!\", \"priority\": \"High\"},\n",
            "    {\"id\": 4, \"subject\": \"Security Alert: Suspicious login detected\", \"priority\": \"High\"},\n",
            "    {\"id\": 1, \"subject\": \"I can't change my profile picture color\", \"priority\": \"Medium\"},\n",
            "    {\"id\": 3, \"subject\": \"Feature request: Dark mode\", \"priority\": \"Low\"}\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# --- The Input Data (Unsorted) ---\n",
        "tickets = [\n",
        "    {\"id\": 1, \"subject\": \"I can't change my profile picture color\"},\n",
        "    {\"id\": 2, \"subject\": \"URGENT: The payment gateway is down, losing money!\"},\n",
        "    {\"id\": 3, \"subject\": \"Feature request: Dark mode\"},\n",
        "    {\"id\": 4, \"subject\": \"Security Alert: Suspicious login detected\"}\n",
        "]\n",
        "\n",
        "# --- The Prioritizer ---\n",
        "# We ask the LLM to return a JSON list sorted by priority.\n",
        "priority_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are a Support Manager.\n",
        "    Analyze the following tickets.\n",
        "    Assign a priority (High, Medium, Low) to each.\n",
        "    Return a JSON list of the tickets SORTED by priority (High first).\n",
        "\n",
        "    Tickets:\n",
        "    {tickets}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "priority_chain = priority_prompt | llm | StrOutputParser()\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"--- ğŸ“¥ Incoming Tickets (Unsorted) ---\")\n",
        "for t in tickets:\n",
        "    print(f\"- {t['subject']}\")\n",
        "\n",
        "print(\"\\n--- ğŸ§  Agent Prioritizing... ---\")\n",
        "sorted_response = priority_chain.invoke({\"tickets\": str(tickets)})\n",
        "\n",
        "# Clean up the response to ensure it's valid JSON (sometimes LLMs add markdown)\n",
        "cleaned_response = sorted_response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "try:\n",
        "    sorted_tickets = json.loads(cleaned_response)\n",
        "    print(\"\\n--- ğŸ“¤ Priority Queue (Sorted) ---\")\n",
        "    for t in sorted_tickets:\n",
        "        # We expect the LLM to have added a 'priority' field\n",
        "        priority = t.get('priority', 'Unknown')\n",
        "        print(f\"[{priority.upper()}] {t['subject']}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing JSON: {e}\\nRaw Output: {sorted_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsAgXW3znZ4m"
      },
      "source": [
        "## Pattern 21: Exploration and Discovery (The Scientist)\n",
        "\n",
        "**The Problem:** Most agents are \"reactive\" (you ask, they answer). But true intelligence involves \"proactive\" discovery asking questions to find information you didn't know you needed.\n",
        "\n",
        "**The Solution:** **The Hypothesis Loop**. The agent looks at a topic, formulates a hypothesis, generates a search query to test it, and then refines its understanding.\n",
        "\n",
        "**The Scenario:** We want to explore \"The future of batteries.\" Instead of just summarizing Wikipedia, the agent will generate *novel questions* to investigate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAExMZv0ne81",
        "outputId": "97998a2b-c317-40fe-d851-10b5efbbcf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”­ Exploring Topic: Solid State Batteries\n",
            "ğŸ§  Starting Knowledge: They are safer and have higher energy density than Li-ion.\n",
            "\n",
            "--- â“ Generated Research Queries ---\n",
            "- \"emerging challenges in solid state battery manufacturing scalability\"\n",
            "- \"recent breakthroughs in solid state battery materials and their implications\"\n",
            "- \"environmental impact of solid state batteries compared to lithium-ion technology\"\n"
          ]
        }
      ],
      "source": [
        "# --- The Explorer ---\n",
        "explorer_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are a Scientific Researcher.\n",
        "    Topic: {topic}\n",
        "    Current Knowledge: {knowledge}\n",
        "\n",
        "    Your goal is to uncover novel or contradictory information.\n",
        "    Generate 3 search queries that would help you find \"unknown unknowns\" about this topic.\n",
        "    Focus on emerging trends or problems.\n",
        "\n",
        "    Return ONLY the 3 queries as a bulleted list.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "explorer_chain = explorer_prompt | llm | StrOutputParser()\n",
        "\n",
        "# --- Execution ---\n",
        "topic = \"Solid State Batteries\"\n",
        "initial_knowledge = \"They are safer and have higher energy density than Li-ion.\"\n",
        "\n",
        "print(f\"ğŸ”­ Exploring Topic: {topic}\")\n",
        "print(f\"ğŸ§  Starting Knowledge: {initial_knowledge}\\n\")\n",
        "\n",
        "# Iteration 1: Generate Questions\n",
        "queries = explorer_chain.invoke({\n",
        "    \"topic\": topic,\n",
        "    \"knowledge\": initial_knowledge\n",
        "})\n",
        "\n",
        "print(\"--- â“ Generated Research Queries ---\")\n",
        "print(queries)\n",
        "\n",
        "# Note: In a full system, you would now:\n",
        "# 1. Feed these queries into a Search Tool (Google/Tavily).\n",
        "# 2. Get the results.\n",
        "# 3. Feed the results back into 'Current Knowledge'.\n",
        "# 4. Repeat the loop to dig deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhtAeN_NoosE"
      },
      "source": [
        "You now possess a toolkit of **21 Patterns** ranging from basic Prompt Chaining to advanced Evaluation and Exploration.\n",
        "\n",
        "### What's Next?\n",
        "1.  **Combine Them:** Real systems use 5-10 patterns at once. (e.g., RAG + Routing + Guardrails + Evaluation).\n",
        "2.  **Move to n8n:** Take these Python concepts and visualize them in n8n workflows for rapid deployment.\n",
        "3.  **Build:** The only way to master this is to build something. Go create an agent that solves a real problem for you.\n",
        "\n",
        "Thank you for coding along!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNJ61GQItJtWJVV+sPh2ang",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
